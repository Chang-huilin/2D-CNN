{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from skimage import color\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image and move to GPU\n",
    "img = cv2.imread(r'C:\\Users\\You\\Desktop\\11.25\\WPS1\\3.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "img_gpu = torch.tensor(img, dtype=torch.float32, device='cuda') / 255.0  # Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image size\n",
    "rows, cols, _ = img.shape\n",
    "\n",
    "# Split the RGB channels\n",
    "r, g, b = img_gpu[:, :, 0], img_gpu[:, :, 1], img_gpu[:, :, 2]\n",
    "\n",
    "# Convert to HSI color space\n",
    "den = torch.sqrt((r - g) ** 2 + (r - b) * (g - b)) + 1e-6  # Avoid division by zero\n",
    "theta = torch.acos(0.5 * ((r - g) + (r - b)) / den)\n",
    "H = theta.clone()\n",
    "H[b > g] = 2 * np.pi - H[b > g]\n",
    "H = H / (2 * np.pi)\n",
    "\n",
    "S = 1 - 3 * torch.min(torch.min(r, g), b) / (r + g + b + 1e-6)\n",
    "I = (r + g + b) / 3\n",
    "\n",
    "# Convert to LAB color space using skimage\n",
    "lab_img = color.rgb2lab(img / 255.0)\n",
    "Lab_l = torch.tensor(lab_img[:, :, 0], dtype=torch.float32, device='cuda')\n",
    "Lab_a = torch.tensor(lab_img[:, :, 1], dtype=torch.float32, device='cuda')\n",
    "Lab_b = torch.tensor(lab_img[:, :, 2], dtype=torch.float32, device='cuda')\n",
    "\n",
    "# Stack features (RGB, HSI, LAB) into a tensor\n",
    "features = torch.stack([r, g, b, H, S, I, Lab_l, Lab_a, Lab_b], dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network (assuming it is already trained and available)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(9, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Load the pre-trained model\n",
    "net = SimpleNN().to('cuda')\n",
    "net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict moisture values\n",
    "moisture_values = torch.zeros((rows, cols), device='cuda')\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        pixel_features = features[i, j, :].view(1, -1)  # Reshape for NN input\n",
    "        predicted_value = net(pixel_features).item()\n",
    "        moisture_values[i, j] = predicted_value\n",
    "\n",
    "# Move results to CPU for visualization\n",
    "moisture_values = moisture_values.cpu().numpy()\n",
    "\n",
    "# Normalize moisture values (clamp between 0 and 100)\n",
    "moisture_values = np.clip(moisture_values, 0, 100)\n",
    "\n",
    "# Plot the original image\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Plot the moisture heatmap\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(moisture_values, cmap='jet')\n",
    "plt.colorbar(label=\"Moisture Content\")\n",
    "plt.title(\"Moisture Heatmap\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "42",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
